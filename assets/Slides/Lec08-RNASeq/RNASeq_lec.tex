
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                                                                   %%
%% This is not the actual talk, we're using this for pasting over to keynote slides  %%
%%                                                                                   %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

\documentclass[red,xcolor={table,usenames,dvipsnames}]{beamer}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
% \usepackage[german,ngerman]{babel}
\usepackage{graphicx}
\usepackage{wrapfig}
\usepackage{calc}
\usepackage[absolute,overlay]{textpos}
\usepackage{multicol}
\usepackage[version=3]{mhchem}
\usepackage{units}
\usepackage{upgreek}
\usepackage{subscript}
\usepackage{colortbl}
\usepackage{array}
\usepackage{ragged2e}
\usepackage{verbatim}
\usepackage{listings}
\usepackage{amsfonts}              % for blackboard bold, etc

\usepackage{amsthm,amsmath,amssymb,mathrsfs}

\usepackage{algorithm2e}
\RestyleAlgo{ruled}
\DontPrintSemicolon
\usepackage{ifthen}
\usepackage[final]{pdfpages}

%---------------------------------------------------------------------------------------
%http://tex.stackexchange.com/questions/65907/beautiful-quotes-in-documentclass-article
\usepackage{epigraph}

\setlength\epigraphwidth{8cm}
\setlength\epigraphrule{0pt}

\usepackage{etoolbox}

\makeatletter
\patchcmd{\epigraph}{\@epitext{#1}}{\itshape\@epitext{#1}}{}{}
\makeatother
%---------------------------------------------------------------------------------------


\mode<presentation>{
  \usetheme{Copenhagen}
  %\usetheme{Madrid}
  %\usecolortheme[rgb={0.97,0.35,0.04}]{structure}
  \usecolortheme{hd2}
  \setbeamercovered{transparent}
}

\renewcommand\emph[1]{\textbf{#1}}
\DeclareMathOperator{\BH}{BH}
\DeclareMathOperator{\Pen}{Pen}
\DeclareMathOperator{\Fdr}{Fdr}
\DeclareMathOperator{\FDR}{FDR}
\DeclareMathOperator{\FDP}{FDP}
\DeclareMathOperator{\fdr}{fdr}
\DeclareMathOperator{\Cfdr}{Cfdr}
\DeclareMathOperator{\argmin}{argmin}

\newcommand{\RR}{\mathbb{R}}
\newcommand{\EE}{\mathbb{E}}
\newcommand{\PP}{\mathbb{P}}
\newcommand{\ind}{\mathbf{1}}

\newcommand{\Hnull}{\mathscr{H}_0}
\newcommand{\allpairs}{((P_i, X_i))_{i \in \{1,\dotsc,m\}}}

%http://tex.stackexchange.com/questions/107186/how-to-write-norm-which-adjusts-its-size
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}

\newtheorem{thm}{Theorem}
\newtheorem{assumption}{Assumption}


\makeatletter
\newcommand{\thickhline}{%
\noalign {\ifnum 0=`}\fi \hrule height 1pt
\futurelet \reserved@a \@xhline
}
\newcolumntype{"}{@{\hskip\tabcolsep\vrule width 1pt\hskip\tabcolsep}}
\makeatother


%\setbeamertemplate{caption}[numbered]
\setbeamerfont{caption}{size=\tiny}
\setbeamercolor{caption name}{fg=darkred}
\setbeamertemplate{enumerate items}[default]
\setbeamertemplate{itemize item}[square]
\setbeamercolor{itemize item}{fg=darkred}
\setbeamertemplate{itemize subitem}[triangle]
\setbeamercolor{itemize subitem}{fg=darkred}
\setbeamertemplate{itemize subsubitem}[circle]
\setbeamercolor{itemize subsubitem}{fg=darkred}

\setbeamertemplate{section in toc}[sections numbered]
\setbeamertemplate{subsection in toc}[square]
\setbeamercolor{subsection number projected}{bg=darkred}

\setbeamercolor{background canvas}{bg=} % for pdfpages

\title{Bios221: RNASeq lecture}

%\subtitle{}

\author{Nikos Ignatiadis}

\institute{Stanford}
\date{July 5, 2018}

%\pgfdeclareimage[height=1cm]{university-logo}{uni-heidelberg-logo}
%\logo{\pgfuseimage{university-logo}}

%\AtBeginPart{
%	\begin{frame}
%		\partpage
%	\end{frame}
%}

%\AtBeginSubsection[]{
%	\begin{frame}<beamer>{Outline}
%		\tableofcontents[currentsection,currentsubsection]
%	\end{frame}
%}


% If you wish to uncover everything in a step-wise fashion, uncomment
% the following command:

%\beamerdefaultoverlayspecification{<+->}


\begin{document}

\begin{frame}
	\titlepage
\end{frame}

%\begin{frame}{Outline}
%	\tableofcontents
%	% You might wish to add the option [pausesections]
%\end{frame}


% Since this a solution template for a generic talk, very little can
% be said about how it should be structured. However, the talk length
% of between 15min and 45min and the theme suggest that you stick to
% the following rules:

% - Exactly two or three sections (other than the summary).
% - At *most* three subsections per section.
% - Talk about 30s to 2min per frame. So there should be between about
%   15 and 30 frames, all told.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{frame}{Poisson testing}



\begin{itemize}
  \item Model:
  \begin{equation*}
\begin{aligned}
Y^{\text{treat}}_{1},\dotsc, Y^{\text{treat}}_{n_1} &\sim \text{Poisson}(\mu_{\text{treat}})\\
Y^{\text{control}}_{1},\dotsc, Y^{\text{control}}_{n_2} &\sim \text{Poisson}(\mu_{\text{control}})
\end{aligned}
\end{equation*}
  \item Estimate: $$\mu_{\text{treat}}, \mu_{\text{control}}$$
  \item Estimate the lfc (log-fold change):
          $$ \text{lfc} = \log_2\left(\frac{\mu_{\text{treat}}}{\mu_{\text{control}}} \right) = \log_2(\mu_{\text{treat}}) - \log_2(\mu_{\text{control}}) $$
  \item Test:

  $$H_0: \mu_{\text{treat}} = \mu_{\text{control}} \;\; (H_0:\text{lfc}=0) $$
\end{itemize}
\end{frame}


\begin{frame}
  $$M = \log_2(\mu_{\text{treat}}) - \log_2(\mu_{\text{control}}) $$

  $$A = \frac{1}{2}\left[\log_2(\mu_{\text{treat}}) + \log_2(\mu_{\text{control}})\right]$$
\end{frame}

% example slide to show what we need to show here..

\begin{frame}
  \begin{itemize}
    \item Recall that we can estimate  $\mu_{\text{treat}}, \mu_{\text{control}}$ using Maximum Likelihood.
    \item This yields the estimators which are just the sample averages:

     $$\hat{\mu}_{\text{treat}} = \frac{1}{n_1} \sum_{i=1}^{n_1} Y^{\text{treat}}_{i}$$
     $$\hat{\mu}_{\text{control}} = \frac{1}{n_2} \sum_{i=1}^{n_1} Y^{\text{control}}_{i}$$

    \item $$ \widehat{\text{lfc}} = \log_2\left(\frac{\hat{\mu}_{\text{treat}}}{\hat{\mu}_{\text{control}}} \right)$$
  \end{itemize}
\end{frame}





\begin{frame}
\begin{itemize}
    \item For our test statistic we would like to use $\widehat{\text{lfc}}$, large values (in magnitude) would provide evidence against the null.
    \item Issue: How to get the distribution under the null hypothesis?
    \item By simulation, for example we could let
    $$\hat{\mu}_0 = \frac{1}{2}\left(\hat{\mu}_{\text{treat}} + \hat{\mu}_{\text{control}}\right)$$
    \item Then for $b=1\dotsc,B$ draw:
  $$\begin{aligned}
Y^{\text{treat}}_{1,b},\dotsc, Y^{\text{treat}}_{n_1,b} &\sim \text{Poisson}(\hat{\mu}_0)\\
Y^{\text{control}}_{1,b},\dotsc, Y^{\text{control}}_{n_2,b} &\sim \text{Poisson}(\hat{\mu}_0)
\end{aligned}
$$
  \item Calculate $\widehat{\text{lfc}}_b$ based on these.
\end{itemize}
\end{frame}

\begin{frame}
\begin{itemize}
    \item Use simulation (or other way) to estimate the standard error $\widehat{se}$, i.e. the standard deviation of $\widehat{\text{lfc}}$, then under the null:

    $$ \frac{\widehat{lfc}}{\widehat{se}} \approx \mathcal{N}(0,1) $$
\end{itemize}
\end{frame}


\begin{frame}{Rewrite what we had}

\begin{itemize}
  \item Let us write:

   $$
   \begin{aligned}
   \log_2(\mu_{\text{treat}}) &= \log_2(\mu_{\text{control}}) + \log_2\left(\frac{\mu_{\text{treat}}}{\mu_{\text{control}}} \right) \\
    &= \beta_0 + \beta_1
   \end{aligned}
   $$

   \item So we can say that for sample $i$:
$$
\log_2(\mu_i)=
\begin{cases}
\beta_0, \text{ if control}\\
\beta_0 + \beta_1,\text{ if treated}\\
\end{cases}
$$
\end{itemize}
\end{frame}




\begin{frame}
  \begin{itemize}
\item Pseudocounts:
 $$\widehat{\text{lfc}} = \log_2\left(\frac{1+\hat{\mu}_{\text{treat}}}{1+\hat{\mu}_{\text{control}}} \right)$$
 \item LIMMA-Voom (Law, Chen, Shi, Smyth 2014)
 \item PoiClaClu package (Witten, 2011)
\end{itemize}
\end{frame}

\begin{frame}
  \begin{itemize}
\item Pseudocounts:
 $$\widehat{\text{lfc}} = \log_2\left(\frac{1+\hat{\mu}_{\text{treat}}}{1+\hat{\mu}_{\text{control}}} \right)$$
 \item LIMMA-Voom (Law, Chen, Shi, Smyth 2014)
 \item PoiClaClu package (Witten, 2011)
\end{itemize}
\end{frame}


\begin{frame}{Bayes}
  $$\text{lfc} \sim \mathcal{N}\left(0,\sigma^2\right)$$
\end{frame}

\begin{frame}{Bayes2}
\begin{itemize}
\item Recall that in our Bayesian lfc estimation we posited:
  $$\text{lfc} \sim \mathcal{N}\left(0,\sigma^2\right)$$
\item Now we can posit this for all genes:
  $$\text{lfc}_g \sim \mathcal{N}\left(0,\sigma^2\right)$$
\item But since we have 20000 genes, we can now estimate $\sigma$ from the data!
\item Intuition: We can plot the distribution of $\widehat{lfc}_g$, if it is wide then $\sigma$ is larger, otherwise small.
\end{itemize}
\end{frame}

\begin{frame}{Gamma-Poisson}
  \begin{itemize}
  \item Model:
  \begin{equation*}
\begin{aligned}
Y^{\text{treat}}_{1},\dotsc, Y^{\text{treat}}_{n_1} &\sim \text{GP}(\mu_{\text{treat}}, \alpha)\\
Y^{\text{control}}_{1},\dotsc, Y^{\text{control}}_{n_2} &\sim \text{GP}(\mu_{\text{control}}, \alpha)\\
\end{aligned}
\end{equation*}
  \item In principle can test again with $\frac{\widehat{lfc}}{\widehat{se}}$
  \item If we want to estimate the standard error, we need to estimate $\alpha$ too.
  \item Possible by maximum likelihood, if we have many replicates (and individual counts not too small)...
  \item For small number of replicates?
\end{itemize}
\end{frame}

\begin{frame}{Challenge 3: Estimating the dispersion}
\begin{itemize}
  \item Recall that the Gamma-Poisson distribution has variance $\mu + \alpha \mu^2$.
  \item Essentially impossible to estimate based on few replicates.
  \item Idea: $\alpha_g$ of different genes are related, hence we can use Empirical Bayes to shrink!
\end{itemize}
\end{frame}

\begin{frame}{Challenge 4: Systematic biases}
\begin{itemize}
  \item Each gene was measured on a different library prep \& sequencing run. 
  \item Maybe there is a systematic bias on the counts we observed (depth of the libraries). For example, there could be numbers $s_1,s_2,s_3,s_4$ such that:
 $$ Y^{\text{treat}}_{1} \sim \text{Poisson}(s_1 \mu_{\text{treat}})$$
 $$ Y^{\text{treat}}_{2} \sim \text{Poisson}(s_2 \mu_{\text{treat}})$$
 $$ Y^{\text{control}}_{1}  \sim \text{Poisson}(s_3 \mu_{\text{control}})$$
 $$ Y^{\text{control}}_{2}  \sim \text{Poisson}(s_4 \mu_{\text{control}})$$
 \item What can we do?
\end{itemize}
\end{frame}

\begin{frame}{Experimental design}

\begin{itemize}
  \item Let us write:

   $$
   \begin{aligned}
   \log_2(\mu_{\text{treat}}) &= \log_2(\mu_{\text{control}}) +\log_2(\mu_{\text{treat}}) -\log_2(\mu_{\text{control}}) \\
   &=\log_2(\mu_{\text{control}}) + \log_2\left(\frac{\mu_{\text{treat}}}{\mu_{\text{control}}} \right) \\
    &= \beta_0 + \beta_1
   \end{aligned}
   $$

   \item So we can say that for sample $i$:
$$
\log_2(\mu_i)=
\begin{cases}
\beta_0, \text{ if control}\\
\beta_0 + \beta_1,\text{ if treated}\\
\end{cases}
$$
\end{itemize}

\end{frame}


\begin{frame}{Experimental design 2}

\begin{itemize}
\item $$
\log_2(\mu_i)=
\begin{cases}
\beta_0, \text{ if control}\\
\beta_0 + \beta_1,\text{ if treated}\\
\end{cases}
$$
\item Now we want to include the technology (paired-end vs single-read) in the analysis as well. Let us define the log-fold change between paired-end and single-read:

$$ \beta_2 = \log_2\left(\frac{\mu_{\text{paired-end}}}{\mu_{\text{single-read}}} \right) $$


\item Then
 $$
\log_2(\mu_i)=
\begin{cases}
\beta_0, \text{ if control and single-read}\\
\beta_0 + \beta_1, \text{ if treated and single-read}\\
\beta_0 + \beta_2, \text{ if control and paired-end}\\
\beta_0 + \beta_1 + \beta_2 \text{ if treated and paired-end}
\end{cases}
$$

\end{itemize}

\end{frame}

\begin{frame}
\begin{itemize}
  \item
 $$
\log_2(\mu_i)=
\begin{cases}
\beta_0, \text{ if control and single-read}\\
\beta_0 + \beta_1, \text{ if treated and single-read}\\
\beta_0 + \beta_2, \text{ if control and paired-end}\\
\beta_0 + \beta_1 + \beta_2 \text{ if treated and paired-end}
\end{cases}
$$
\item Compact notation: Write $x_{i1} = 1$ if treated and $0$ otherwise, and $x_{i2}=1$ if paired-end and $0$ otherwise, then
$$\log_2(\mu_i) = \beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2}$$
\end{itemize}
\end{frame}


\begin{frame}{Advanced: GLMs}
  \begin{itemize}
    \item Can generalize this even further to:
      $$\log(\mu_i) = \beta_0 + \sum_{j=1}^p x_{ij} \beta_j$$
    \item Upshot: "Generalized Linear Models" are well studied, all methods described generalize to this setting.
    \item Usually expressed in terms of a design matrix
  \end{itemize}
\end{frame}

\begin{frame}{banded}
\begin{itemize}
  \item So far our null hypothesis has been:

  $$H_0: \text{lfc} = 0 $$

  \item But what if we do not care about $|\text{lfc}|\leq 1$? We can express this as a new null hypothesis:

  $$H_0: |\text{lfc}| \leq 1$$
\end{itemize}
\end{frame}





\end{document}
