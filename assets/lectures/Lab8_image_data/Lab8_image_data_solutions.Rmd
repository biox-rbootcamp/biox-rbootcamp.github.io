---
title: 'Lab 8 Solutions: Image Data'
author: "Bios 221: Modern Statistics for Modern Biology"
date: "10/16/2019"
output: 
  html_document:
    toc: true
    toc_float: true
---


# Goal

In this lab we will learn the basics of analysis imaging data. There is a 
corresponding quiz on [Canvas](https://canvas.stanford.edu) -- the questions 
are dispersed throughout this lab (called Quiz question). There are also 
additional questions which you do not have to turn in. 

# Setup

Install packages.

```{r installation, warning=FALSE, message=FALSE}
pkgs_needed = c("EBImage","magrittr","tibble","ggplot2","genefilter",
                "GGally", "MSMB")
letsinstall = setdiff(pkgs_needed, installed.packages()) 
if (length(letsinstall) > 0) {
  BiocManager::install(letsinstall)
}
```

Load packages.

```{r setup, warning=FALSE, message=FALSE}
library("EBImage")
library("magrittr")
library("tibble")
library("ggplot2")
library("genefilter")
library("GGally")
knitr::opts_chunk$set(echo = TRUE)
```

# Loading images

A useful toolkit for handling images in R is the Bioconductor package `EBImage`. 
We start out by reading in a simple picture to demonstrate the basic functions.

```{r data1, fig.cap=""}
imagefile = system.file("images", "mosquito.png",
                        package = "MSMB")
mosq = readImage(imagefile)
```

# Displaying images

Let's visualize the image that we just read in. The basic function is `display` from the `EBImage` package.
If you do this from the R console (instead of knitting the document), then this 
will allow you to zoom in and scroll around.

```{r vis1}
EBImage::display(mosq)
```

We can also display the image using R's built-in plotting by calling
`display` with the argument `method = "raster"`.  The image then goes to
the current device.  In this way, we can combine image data with other plotting
functionality, for instance, to add text labels.

```{r mosquito}
EBImage::display(mosq, method = "raster")
text(x = 85, y = 800, label = "A mosquito",
     adj = 0, col = "orange", cex = 1.5)
```

Note that we can also read and view color images.

```{r vis3a}
imagefile = system.file("images", "hiv.png", package = "MSMB")
hivc = readImage(imagefile)
EBImage::display(hivc, method = "raster")
```

Furthermore, if an image has multiple frames, they can be displayed all at once in a grid
arrangement by specifying the function argument `all = TRUE`,

```{r nucleitiled, dev = "png"}
nuc = readImage(system.file("images", "nuclei.tif", package = "EBImage"))
EBImage::display(1 - nuc, method = "raster", all = TRUE)
```

or we can just view a single frame, for instance, the second one.

```{r nucleitiledoneframe, dev = "png"}
EBImage::display(1 - nuc, method = "raster", frame = 2)
```

**Quiz question 1**: What is the smallest value in the `nuc` frames?

**Answer:**

```{r}
min(nuc@.Data)
```

**Quiz question 2**: What is the largest value in the `nuc` frames?

**Answer:**
  
```{r}
max(nuc@.Data)
```

**Quiz question 3**: What does `1 - nuc` do?

**Answer:**
  
  Inverts the `nuc` image
  
# Writing images to file

We read the image `hivc` from a file in PNG format, so let's now write it out 
as a JPEG file. The underlying JPEG software library lets us choose a quality 
value between 1 and 100 as a parameter for its compression algorithm,
which is exposed in the `writeImage` function by its argument `quality`. 
The default value is 100. Here we use a smaller value. This leads to smaller 
file size at the cost of some reduction in image quality.

```{r write1}
writeImage(hivc, "hivc.jpeg", quality = 85)
```

# How are images stored in R?

Let's dig into what's going on by first identifying the class of the images 
we are plotting:

```{r how1}
class(mosq)
```

So we see that this object has the class `Image`. This is not one of the base 
R classes, rather, it is defined by the package `EBImage`. We can find out more 
about this class through the help browser or by typing `?Image`. The class is
derived from the base R class `array`, so you can do with `Image` objects 
everything that you can do with R arrays; in addition, they have some extra 
features and  behaviors. In R's parlance, the extra features are called slots 
and the behaviors are called methods; methods are a special kind of function.

**Quiz question 4**: How many slots does an `Image` object have?

  
**Answer:** 2 

```{r}
slotNames(hivc)
```

**Quiz question 5**: What is the pixel value of `mosq` at position `[1,1]`? 

**Answer:** 0.196
  
```{r}
mosq[1,1]
```

The dimensions of the image can be extracted using the `dim` method, just like 
for regular arrays.

```{r dim}
dim(mosq)
```

The `hist` method has been redefined:

```{r mosqhist, fig.width=4, fig.height=4}
hist(mosq)
```

If we want to directly access the data matrix as an R `array`, we can use the
accessor function `imageData`:

```{r how3}
imageData(mosq)[1:3, 1:6]
```

Compare `mosq` and `hivc`.

```{r show3, echo=FALSE}
mosq
hivc
```

**Quiz question 6**: How many color channels are in `mosq`?

**Answer:** 1


**Quiz question 7**: How many color channels are in `hivc`?

**Answer:** 3


The two images differ by their property `colorMode`, which is `Grayscale`
for `mosq` and `Color` for `hivc`. What is the point of this property? 
It turns out to be convenient when we are dealing with stacks of images.  If
`colorMode` is `Grayscale`, then the third and all higher dimensions of the
array are considered as separate image frames corresponding, for instance, to
different $z$-positions, time points, replicates, etc.  On the other hand, if
`colorMode` is `Color`, then the three dimensions are assumed to hold
different color channels, and only the fourth and higher dimensions -- 
if present -- are used for multiple image frames. 

**Quiz question 8**: How many color channels are in `nuc`?

**Answer:** 1


R stores the data `nuc` as

```{r how6}
nuc
dim(imageData(nuc))
```

We see that we have 4 frames in total, which correspond to the 4 separate images `frames.render`.

# Manipulating images

Now that we know that images are stored as arrays of numbers in R, our method of
manipulating images becomes clear -- simple algebra!  For example, we can take our
original image and flip the bright areas to dark and vice versa by simply 
subtracting the image from its maximum value, 1. 

```{r manip1a}
mosqinv = 1 - mosq
EBImage::display(mosqinv, method = "raster")
```

Here we use the fact that we know the minimum and maximum values 
of the image to be 0 and 1.  In the more general case, the expression
`normalize(-mosq)` would be safer.

```{r manip1b}
EBImage::display(normalize(-mosq), method = "raster")
```

We could also adjust the contrast through multiplication 

```{r manip3a}
mosqcont = mosq * 3
EBImage::display(mosqcont, method = "raster")
```

and the gamma-factor through exponentiation.

```{r manip3b}
mosqexp = mosq ^ (1/3)
EBImage::display(mosqexp, method = "raster")
```

Furthermore, we can crop, 

```{r manip4a}
mosqcrop   = mosq[100:438, 112:550]
EBImage::display(mosqcrop, method = "raster")
```

threshold  

```{r manip4b}
mosqthresh = mosq > 0.5
EBImage::display(mosqthresh, method = "raster")
```

and transpose images with matrix operations

```{r manip4c}
mosqtransp = transpose(mosq)
EBImage::display(mosqtransp, method = "raster")
```

**Quiz question 9**: What is the object class of `mosqthresh`, the result of 
the thresholding?

**Answer:** `EBImage`

```{r}
str(mosqthresh)
```

# Spatial transformations

We just saw one type of spatial transformation, transposition, but there are 
many more -- here are some examples:

```{r spattrans1}
mosqrot   = EBImage::rotate(mosq, angle = 30)
mosqshift = translate(mosq, v = c(40, 70))
mosqflip  = flip(mosq)
mosqflop  = flop(mosq)
```

`rotate` rotates the image clockwise with the given angle, `translate` moves 
the image by the specified two-dimensional vector (pixels that end up outside 
the image region are cropped, and pixels that enter into the image region are 
set to zero). The functions `flip` and  `flop` reflect the image around the 
central horizontal and vertical axis, respectively.

Plot them:

```{r}
# TODO
```

# Linear filters

Let's now switch to an application in cell biology. We load images of human 
cancer cells that were studied by Laufer, Fischer and co-workers (Laufer et al. 2013). 

```{r MSBdata, results="hide"}
imagefiles = system.file("images", 
                         c("image-DAPI.tif", "image-FITC.tif", "image-Cy3.tif"),
                         package="MSMB")
cells = readImage(imagefiles)
cells
```

Our goal now is to computationally identify and quantitatively characterize the 
cells in these images. However, before we can start with real work, we need to 
deal with a slightly mundane data conversion issue. This is, of course, not 
unusual. Let us inspect the dynamic range (the minimum and the maximum value) 
of the images.

```{r range}
apply(cells, 3, range)
```

We see that the maximum values are small numbers well below 1. 
We can rescale these data to approximately cover the range $[0,1]$ as

```{r fixrange}
cells[,,1] = 32 * cells[,,1]
cells[,,2:3] = 16 * cells[,,2:3]
apply(cells, 3, range)
```

**Quiz question 10**: How big is the `cells` object in Râ€™s memory in Mb? Hint: 
Use `object.size` and `format` functions.

**Answer:**  

```{r}
format(object.size(cells), units="Mb") 
```  

Our first goal is segmentation of the images to identify the individual cells. We can start by removing local artifacts or noise from the images through 
smoothing.  We use a Gaussian kernel to compute a weighed average intensity 
at all pixel positions. In `EBImage`, this can be is implemented by the function 
`makeBrush` and `filter2`.

```{r defw, fig.width = 3, fig.height = 2.6}
w = makeBrush(size = 51, shape = "gaussian", sigma = 7)
tibble(w = w[(nrow(w)+1)/2, ]) %>%
  ggplot(aes(y = w, x = seq(along = w))) + geom_point()
```  

```{r filter2}
nucSmooth = filter2(getFrame(cells, 1), w)
EBImage::display(nucSmooth, method = "raster")
```

**Quiz question 11**: What happens if you decrease the brush size?

**Answer:**
    Image is less blurred
    
To proceed, we now, however, use smaller smoothing bandwidths than what we displayed. 
Let's use a `sigma` of 1 pixel for the DNA channel and 3 pixels for actin and tubulin.

```{r smooth}
cellsSmooth = Image(dim = dim(cells))
sigma = c(1, 3, 3)
for(i in seq_along(sigma)) {
  cellsSmooth[, ,i] = filter2( 
    cells[,,i],
    filter = makeBrush(size = 51, shape = "gaussian",
    sigma = sigma[i])
  )
}
EBImage::display(cellsSmooth, method = "raster", all = TRUE)
```

# Adaptive thresholding

We now define a smoothing window, `disc`, whose size is 21 pixels, and therefore 
bigger than the nuclei we want to detect, but small compared to the length 
scales of the illumination artifact. We use it to threshold the smoothed image.

```{r hresh}
disc = makeBrush(21, "disc")
disc = disc / sum(disc)
offset = 0.02
nucThresh = (cellsSmooth[,,1] - filter2( cellsSmooth[,,1], disc ) > offset)
EBImage::display(nucThresh, method = "raster")
```

# Morphological operations on binary images

The thresholded image `nucThresh` is not yet satisfactory. The boundaries of 
the nuclei are slightly rugged, and there is noise at the single-pixel level.
An effective and simple way to remove these nuisances is given by a set 
of morphological operations

Let us apply a morphological opening to our image.

```{r morphopen1}
nucOpened = EBImage::opening(nucThresh, kern = makeBrush(3, shape = "disc"))
EBImage::display(nucOpened, method = "raster")
```

The result of this is subtle, and you will have to zoom into the images in
to spot the differences, but this operation manages to smoothen out some 
pixel-level features in the binary images that for our application are 
undesirable.


# Segmentation of a binary image into objects

The binary image `nucOpened` represents a segmentation of the image into 
foreground and background pixels, but not into individual nuclei.
We can take one step further and extract individual objects defined as connected
sets of pixels. In `EBImage`, there is a handy function for this purpose, 
`bwlabel`.

```{r imageProcessing14}
nucSeed = bwlabel(nucOpened)
```

The function returns an image, `nucSeed`, of integer values, where 0 represents
the background, and the integers equal and greater to 1 are indices of different 
identified objects.

**Quiz question  12**: What is the index of the second largest cell in `nucSeed`?
Hint: Use `table` function.

**Answer:** 1
    
```{r}
sort(table(nucSeed), decreasing = TRUE)
```

We could use this information to remove objects that are too large or too small 
compared to what we expect.

To visualize such images, the function `colorLabels` is convenient, which converts
the (grayscale) integer image into a color image, using distinct, arbitrarily chosen
colors for each object.

```{r imageProcessing17, eval = FALSE}
EBImage::display(colorLabels(nucSeed), method = "raster")
```

The result is already encouraging, although we can spot two types of errors:

* Some neighboring objects were not properly separated.
* Some objects contain holes.

For statistical analyses of high-throughput images, we may choose to be satisfied
with a simple method that does not rely on too many parameters or assumptions
and results in a perhaps sub-optimal but rapid and good enough result.
In this spirit, let us proceed with what we have. We generate a lenient 
foreground mask, which surely covers all nuclear stained regions, even though 
it also covers some regions between nuclei. To do so, we simply apply a second, 
less stringent adaptive thresholding.

```{r imageProcessing15a}
nucMask = cellsSmooth[,, 1] - filter2(cellsSmooth[ , , 1], disc) > 0
```

and apply another morphological operation, `fillHull`, which fills holes that 
are surrounded by foreground pixels.

```{r imageProcessing15b}
nucMask = fillHull(nucMask)
```

To improve `nucSeed, we can now `propagate` its segmented objects until they
fill the mask defined by `nucMask`. Boundaries between nuclei, in those
places where the mask is connected, can be drawn by Voronoi tessellation, 
which is implemented in the function `propagate`.

```{r imageProcessing16}
nuclei = propagate(cellsSmooth[,,1], nucSeed, mask = nucMask)
EBImage::display(nuclei,method = "raster")
```

# Segmenting the cell bodies

To determine a mask of cytoplasmic area in the images, let us explore a different way of
thresholding, this time using a global threshold which we find by fitting a mixture model
to the data. The histograms show the distributions of the pixel intensities in the actin
image. We look at the data on the logarithmic scale, and 
zoom into the region where most of the data lie.

```{r histcellbody, fig.width = 4, fig.height = 4}
hist( log(cellsSmooth[,,3]) )
```

```{r histcellbody2, fig.width = 4, fig.height = 4}
hist( log(cellsSmooth[,,3]), xlim = -c(3.6, 3.1), breaks = 300)
```

Looking at the these histograms for many images, we can set up the following 
model for the purpose of segmentation: the signal in the cytoplasmic channels
of `cellsSmooth` is a mixture of two distributions, a log-Normal background 
and a foreground with another, unspecified, rather flat, but mostly 
non-overlapping distribution.  Moreover the majority of pixels are
from the background.

Code for estimating mixture parameters:

```{r musigmaEstimator, message=FALSE}
library("genefilter")
bgPars = function(x) {
  x    = log(x)
  loc  = half.range.mode( x )
  left = (x - loc)[ x < loc ]
  wid  = sqrt( mean(left^2) )
  c(loc = loc, wid = wid, thr = loc + 6*wid)
}
cellBg = apply(cellsSmooth, MARGIN = 3, FUN = bgPars)
cellBg
```

Visualizing of estimated parameters:

```{r hcb, fig.width = 4, fig.height = 4}
hist(log(cellsSmooth[,, 3]), xlim = -c(3.6, 3.1), breaks = 300)
abline(v = cellBg[c("loc", "thr"), 3], col = c("brown", "red"))
```

Thresholding to obtain cell bodies.

```{r cytoplasmMask}
cytoplasmMask = (cellsSmooth[,,2] > exp(cellBg["thr", 2])) |
       nuclei | (cellsSmooth[,,3] > exp(cellBg["thr", 3]))
EBImage::display(cytoplasmMask, method = "raster")
```

Dividing into cells:

```{r imageProcessing22}
cellbodies = propagate(x = cellsSmooth[ , , 3], seeds = nuclei,
                       lambda = 1.0e-2, mask = cytoplasmMask)
EBImage::display(colorLabels(cellbodies), method = "raster")
```

Overlay nuclei segmentation on first channel:

```{r imageProcessing25}
nucSegOnNuc  = paintObjects(nuclei, tgt = toRGB(cells[, , 1]), col = "#ffff00")
EBImage::display(nucSegOnNuc, method = "raster")
```

Overlay nuclei segmentation with all three channels:

```{r}
cellsColor = rgbImage(red   = cells[,, 3], 
                      green = cells[,, 2], 
                      blue  = cells[,, 1])
nucSegOnAll  = paintObjects(nuclei, tgt = cellsColor, col = "#ffff00")
EBImage::display(nucSegOnAll, method = "raster")
```

Overlay segmented cell bodies.

```{r}
cellSegOnAll = paintObjects(cellbodies, tgt = nucSegOnAll, col = "#ff0080")
EBImage::display(cellSegOnAll, method = "raster")
```

# Feature extraction

Now that we have the segmentations `nuclei` and `cellbodies` together with
the original image data `cells`, we can compute various descriptors, or features,
for each cell.  We use the base R function `table` to determine the total number 
and sizes of the objects.

Let us now take this further and compute the mean intensity of the DAPI 
signal(`cells[,, 1]`) in the segmented nuclei, the mean actin intensity
(`cells[,, 3]`) in the segmented nuclei and the mean actin intensity in 
the cell bodies.

```{r baserfeats}
meanNucInt       = tapply(cells[,,1], nuclei, mean)
meanActIntInNuc  = tapply(cells[,,3], nuclei, mean)
meanActIntInCell = tapply(cells[,,3], cellbodies, mean)
```

We can visualize the features in pairwise scatterplots. We see
that they are correlated with each other, although each feature also carries independent
information.

```{r pairsint, fig.width = 5.3, fig.height = 5.3}
library("GGally")
ggpairs(tibble(meanNucInt, meanActIntInNuc, meanActIntInCell))
```

In fact, `EBImage` provides a convenience function `computeFeatures` that 
automatically and efficiently computes many commonly used features. Below, we 
compute features for intensity, shape and texture for each cell from the DAPI 
channel using the nucleus segmentation (`nuclei`) and from the actin and tubulin
channels using the cell body segmentation (`cytoplasmRegions`).


```{r}
F1 = computeFeatures(nuclei,     cells[,,1], xname = "nuc",
                                             refnames = "nuc")
F2 = computeFeatures(cellbodies, cells[,,2], xname = "cell",
                                             refnames = "tub")
F3 = computeFeatures(cellbodies, cells[,,3], xname = "cell",
                                             refnames = "act")
dim(F1)
```

F1 is a matrix with 43 rows (one for each cell) and 89 columns, one for each 
of the computed features.

```{r}
F1[1:3, 1:5]
```


The column names encode the type of feature, as well the color channel(s) and 
segmentation mask on which it was computed. For example, we could now use 
multivariate analysis methods to draw inferences about our dataset.


