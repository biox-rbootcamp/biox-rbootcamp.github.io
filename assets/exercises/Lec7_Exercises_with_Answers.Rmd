---
title: "Lecture 7: Exercises with Answers"
date: October 18th, 2018
output: 
  html_notebook:
    toc: true
    toc_float: true
---

```{r}
library(tidyverse)
```


# Exercise 1: Hypothesis testing

Similarly to dataset `mtcars`, the dataset `mpg` from `ggplot` package 
includes data on automobiles. However, `mpg` includes data for newer
cars from year 1999 and 2008. The variables measured for each car is slighly 
different. Here we are interested in the variable, `hwy`, the highway miles per 
gallon.


```{r}
# We first format the column trans to contain only info on transmission auto/manual
mpg
mpg <- mpg %>% 
  mutate(
    transmission = factor(
        gsub("\\((.*)", "", trans), levels = c("auto", "manual"))
  )
mpg
```

## Part 1: One-sample test

a. Subset the `mpg` dataset to inlude only cars from  year 2008.

```{r}
mpg2008 <- mpg %>% 
  filter(year == 2008)
```

b. Test whether cars from 2008 have mean the highway miles per gallon, `hwy`, 
equal to 30 mpg.

```{r}
t.test(mpg2008$hwy, mu = 30, alternative = "two.sided")
```

c. Test whether cars from 2008 with 4 cylinders have mean `hwy` equal to 30 mpg.

```{r}
mpg2008_4cyl <- mpg %>% 
  filter(year == 2008, cyl == 4)

t.test(mpg2008_4cyl$hwy, mu = 30, alternative = "two.sided")
```

## Part 2: Two-sample test

a. Test if the mean `hwy` for automatic is **less than** that for manual cars
**in 2008**. Generate a boxplot with jittered points for `hwy` for each 
transmission group.

```{r}
t.test(data = mpg2008, hwy ~ transmission, alternative = "less")
# or
# t.test(x = mpg2008 %>% filter(transmission == "auto") %>% pull(hwy),
#        y = mpg2008 %>% filter(transmission == "manual") %>% pull(hwy), 
#        alternative = "less")
```

```{r}
ggplot(mpg2008, aes(x = transmission, y = hwy)) +
  geom_boxplot() + geom_jitter(height = 0, width = 0.2)
```

b. Test if the mean `hwy` for cars from 1999 and is greater than that for
cars from 2008. Generate a boxplot with jittered points
for `hwy` for each year group.

```{r}
t.test(data = mpg, hwy ~ year, alternative = "greater")
```

```{r}
ggplot(mpg, aes(x = factor(year), y = hwy)) +
  geom_boxplot() + geom_jitter(height = 0, width = 0.2)
```



# Exercise 2: Logistic Regression

In this you will use a dataset `Default`, on customer default records for 
a credit card company, which is included in [ISL book](www.statlearning.com). 
To obtain the data you will need to install a package `ISLR`.

```{r}
# install.packages("ISLR")
library(ISLR)
(Default <- tbl_df(Default))
```


a. First, divide your dataset into a train and test set. Randomly sample
6000 observations and include them in the train set, and the remaining use
as a test set.

```{r}
train.idx <- sample(1:nrow(Default), 6000, replace = FALSE)
train <- Default[train.idx, ]
test <- Default[-train.idx, ]
```

b. Fit a logistic regression including all the features to predict
whether a customer defaulted or not.

```{r}
fit.logit <- glm(default ~ student + balance + income, data = train, 
                 family = "binomial")
summary(fit.logit)
```

c. Note if any variables seem not significant. Then, adjust your model
accordingly (by removing them).

```{r}
fit.logit <- glm(default ~ student + balance, data = train, 
                 family = "binomial")
summary(fit.logit)
```

d. Compute the predicted probabilities of 'default' for the observations
in the test set. Then evaluate the model accuracy.

```{r}
pred.prob.default <- predict(fit.logit, test, type = "response")
pred.default <- factor(pred.prob.default > 0.5, levels = c(FALSE, TRUE),
                       labels = c( "No", "Yes"))
(tab <- table(pred = pred.default, true = test$default))
(accuracy <- sum(diag(tab))/nrow(test))
```


d. For the test set, generate a scatterplot of 'balance' vs 'default' 
with points colored by 'student' factor. Then, overlay a line plot 
of the predicted probability of default as computed in the previous question.
You should plot two lines for student and non student separately by setting 
the 'color = student'.


```{r}
train$default.numeric <- as.numeric(train$default) - 1
test$default.numeric <- as.numeric(test$default) - 1

ggplot(test, aes(x = balance, color = student)) +
  geom_point(aes(y = default.numeric)) + 
  geom_line(aes(y = pred.prob.default), lwd = 1)
```




# Exercise 3: Random Forest

In this exercise we will build a random forest model based
on the data used to create the visualization [here](http://www.r2d3.us/visual-intro-to-machine-learning-part-1/).

```{r}
# Skip first 2 lines since they were comments
url <- paste0("https://raw.githubusercontent.com/jadeyee/r2d3-part-1-data/",
              "master/part_1_data.csv")
houses <- read.csv(url, skip = 2)
houses <- tbl_df(houses)
houses <- houses %>%
    mutate(city = factor(in_sf, levels = c(1, 0), labels = c("SF", "NYC")))
houses 
```

a. Using `pairs()` function plot the relationship between every variable pairs.
You can color the points by the city the observation corresponds to; set the color argument 
in `pairs()` as follows: `col = houses$in_sf + 3L` 

```{r, fig.width=8, fig.height=7}
city.colors <- houses$in_sf + 3L
pairs(houses[, -1], col = city.colors, pch = 16)
```

b. Split the data into (70%-30%) train and test set.
How many observations are in your train and test sets?


```{r}
set.seed(123)
train.idx <- sample(nrow(houses), 0.7 * nrow(houses))
train <- houses[train.idx, ]
test <- houses[-train.idx, ]
dim(train)
dim(test)
```

c. Train a random forest on the train set, using all the variables in the model,
to classify houses into the ones from San Francisco and from New York.
Remember to remove 'in_sf', as it is the same variable as 'city'. 

```{r}
library(randomForest)
houses.rf <- randomForest(city ~ . -in_sf, data = train, importance = TRUE, proximity = TRUE)
houses.rf
```

d. Compute predictions and print out 
[the confusion (error) matrix](https://en.wikipedia.org/wiki/Confusion_matrix)
for the test set to asses the model accuracy. Also, compute the model 
accuracy.

```{r}
pred <- predict(houses.rf, newdata = test)
(confusion.mat <- table(pred, truth = test$city))
(accuracy <- sum(diag(confusion.mat))/nrow(test))
```

e. Which features were the most predictive for classifying houses into SF vs NYC groups?
Use importance measures to answer the question.

```{r}
varImpPlot(houses.rf)
```






